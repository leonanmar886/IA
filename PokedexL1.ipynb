{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "uEmwiyXsI3zz",
      "metadata": {
        "id": "uEmwiyXsI3zz"
      },
      "source": [
        "# **Trabalho Final - Inteligência Artificial - Classificação de Pokémon**\n",
        "\n",
        "*Equipe:*\n",
        "- Anna Beatriz - 538758\n",
        "- Kauan Soares - 537063\n",
        "- Leonan Marques - 539000\n",
        "- Victoria Moura - 541801\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "_RSWETr5Jaaz",
      "metadata": {
        "id": "_RSWETr5Jaaz"
      },
      "source": [
        "# **Contextualização e Conceitos Utilizados**\n",
        "\n",
        "\n",
        "\n",
        "A proposta principal do nosso trabalho é criar um modelo de I.A que seja capaz de identificar qual Pokemón aparece em cada imagem dentre um conjunto de imagens. Para isso, utilizamos uma abordagem baseada em Redes Neurais Convolucionais (CNNs), que são amplamente usadas para análise e reconhecimento de imagens.\n",
        "\n",
        "No entanto, para que a CNN consiga aprender a distinguir cada Pokémon corretamente, faremos uso de aprendizado supervisionado. Isso significa que fornecemos ao modelo imagens já rotuladas, indicando a qual Pokémon cada uma pertence, e o modelo aprende, com base nesses exemplos, a fazer suas próprias previsões.\n",
        "\n",
        "No nosso projeto, estruturamos a CNN com camadas especializadas:\n",
        "-  Camadas *Convolucionais*, que identificam padrões locais nas imagens, como contornos e cores distintas.\n",
        "- Camadas de *Pooling*, que reduzem a dimensionalidade da imagem, tornando o modelo mais eficiente.\n",
        "- Camadas *Densas*, que combinam as informações extraídas e fazem a predição final do Pokémon.\n",
        "\n",
        "Essa arquitetura permite que o modelo aprenda progressivamente a reconhecer características específicas de cada Pokémon e utilize essas informações para classificá-los corretamente."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "LXLMoHL2JfnC",
      "metadata": {
        "id": "LXLMoHL2JfnC"
      },
      "source": [
        "# **Imports e inicialização**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f219de6",
      "metadata": {
        "id": "1f219de6",
        "outputId": "66f7552e-d7ab-4f49-a2aa-f119636e7c48"
      },
      "outputs": [],
      "source": [
        "%pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "356bc245-c7d7-4224-aca4-7da5e4da390a",
      "metadata": {
        "id": "356bc245-c7d7-4224-aca4-7da5e4da390a",
        "tags": []
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.metrics import Precision, Recall\n",
        "from sklearn.metrics import f1_score\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fU43sCa4JkQ6",
      "metadata": {
        "id": "fU43sCa4JkQ6"
      },
      "source": [
        "# **Tratamento dos dados**\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "897cd255-25a8-4596-a1b0-6ea381814818",
      "metadata": {
        "id": "897cd255-25a8-4596-a1b0-6ea381814818"
      },
      "source": [
        "O dataset traz um código que ja divide as imagens em 80% treino, 10% validação e 10% teste"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "150eb47b-d821-42ca-b782-a0345ae1fa44",
      "metadata": {
        "id": "150eb47b-d821-42ca-b782-a0345ae1fa44",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Definir diretórios dos conjuntos de imagens\n",
        "train_dir = \"./pokemon-dataset-1000 - Copia/train\"\n",
        "val_dir = \"./pokemon-dataset-1000 - Copia/val\"\n",
        "test_dir = \"./pokemon-dataset-1000 - Copia/test\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "522f8aa7-38f3-4e8e-ae4b-cd68eac15224",
      "metadata": {
        "id": "522f8aa7-38f3-4e8e-ae4b-cd68eac15224"
      },
      "source": [
        "**`train_dir`**: Conjunto de imagens usado para treinar o modelo.\n",
        "\n",
        "**`val_dir`**: Conjunto de imagens usado para validar o modelo durante o treinamento.\n",
        "\n",
        "**`test_dir`**: Conjunto de imagens usado para avaliar o desempenho do modelo após o treinamento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c4a40eed-4c41-4b87-a054-bb63de6334c4",
      "metadata": {
        "id": "c4a40eed-4c41-4b87-a054-bb63de6334c4",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Parâmetros\n",
        "img_size = (128, 128)\n",
        "batch_size = 32"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "29884af8-2390-401e-a7f5-e4e31f666404",
      "metadata": {
        "id": "29884af8-2390-401e-a7f5-e4e31f666404"
      },
      "source": [
        "**`img_size`** : Define o tamanho de cada imagem que será alimentada ao modelo. Como o modelo de CNN está criando está lidando com imagens, é necessário garantir que todas as imagens sejam redimensionadas para um tamanho comum antes de serem passadas para a rede.  \n",
        "\n",
        "**`batch_size`** : Define o número de imagens que serão passadas pela rede neural em uma única iteração durante o treinamento.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3890bddf-8eba-4891-a90a-448b4871a8af",
      "metadata": {
        "id": "3890bddf-8eba-4891-a90a-448b4871a8af",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Pré-processamento das imagens\n",
        "train_datagen = ImageDataGenerator(rescale=1.0 / 255.0)\n",
        "val_datagen = ImageDataGenerator(rescale=1.0 / 255.0)\n",
        "test_datagen = ImageDataGenerator(rescale=1.0 / 255.0)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fcf53ce8-21f7-4e63-90ec-1a958934be8a",
      "metadata": {
        "id": "fcf53ce8-21f7-4e63-90ec-1a958934be8a"
      },
      "source": [
        "**OBS:** A normalização ajuda a acelerar o processo de treinamento, pois pode reduzir a variabilidade nos gradientes e melhorar a convergência. Também pode ajudar o modelo a se ajustar de maneira mais eficiente aos dados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f8662ea-ce09-44f5-b259-3fc64a436c04",
      "metadata": {
        "id": "0f8662ea-ce09-44f5-b259-3fc64a436c04",
        "outputId": "55c31ec6-7311-4e89-842c-214ed192de61",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Criar os geradores de dados (Treino, Teste e Validação)\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir, target_size=img_size, batch_size=batch_size, class_mode=\"categorical\"\n",
        ")\n",
        "val_generator = val_datagen.flow_from_directory(\n",
        "    val_dir, target_size=img_size, batch_size=batch_size, class_mode=\"categorical\"\n",
        ")\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir, target_size=img_size, batch_size=batch_size, class_mode=\"categorical\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9477b8fe",
      "metadata": {
        "id": "9477b8fe"
      },
      "source": [
        "**`train_datagen:`** Este é o objeto de pré-processamento que foi configurado anteriormente (com a normalização dos pixels e, possivelmente, aumentos de dados, caso tenha sido configurado).  \n",
        "\n",
        "**`flow_from_directory(train_dir):`** Este método cria um gerador que irá buscar as imagens no diretório train_dir (diretório que contém as imagens de treinamento). As imagens devem estar organizadas em subpastas, onde cada subpasta representa uma classe. O nome da subpasta será usado como o rótulo da classe.  \n",
        "\n",
        "**`class_mode=\"categorical\":`** Como estamos tratando um problema de classificação multiclasse, este parâmetro indica que as labels (rótulos) serão codificadas de forma categórica. Ou seja, para cada imagem, a saída será um vetor \"one-hot\" representando a classe da imagem."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af669c16-d1b7-4999-817c-f4ac07da53dd",
      "metadata": {
        "id": "af669c16-d1b7-4999-817c-f4ac07da53dd",
        "outputId": "dc1dc7bd-b7f1-4033-86b4-fd579af08122",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Visualizar 5 exemplos do conjunto de treino\n",
        "class_names = list(train_generator.class_indices.keys())\n",
        "num_examples = 5\n",
        "\n",
        "fig, axes = plt.subplots(1, num_examples, figsize=(15, 5))\n",
        "train_images, train_labels = next(train_generator)\n",
        "\n",
        "for i in range(num_examples):\n",
        "    img = train_images[i]\n",
        "    axes[i].imshow(img)\n",
        "    axes[i].set_title(f\"Classe: {class_names[np.argmax(train_labels[i])]} \")\n",
        "    axes[i].axis(\"off\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3878f4be-76ff-42ad-ada1-d787d04acd69",
      "metadata": {
        "id": "3878f4be-76ff-42ad-ada1-d787d04acd69"
      },
      "source": [
        "A classe F1Score herda de tf.keras.metrics.Metric, o que permite criar métricas personalizadas para serem usadas com o TensorFlow/Keras.  \n",
        "Definimos duas métricas auxiliares: Precision e Recall (essas duas métricas serão usadas para calcular o F1-Score.)  \n",
        "\n",
        "**OBS**: `Precision` mede a proporção de predições positivas corretas, e `recall` mede a proporção de instâncias positivas que foram corretamente identificadas, ou seja, quantas das instâncias reais positivas foram capturadas pelo modelo.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a663584-76fd-4711-a517-eaa49e7fbb53",
      "metadata": {
        "id": "5a663584-76fd-4711-a517-eaa49e7fbb53",
        "tags": []
      },
      "outputs": [],
      "source": [
        "class F1Score(tf.keras.metrics.Metric):\n",
        "    def __init__(self, name=\"f1_score\", **kwargs):\n",
        "        super(F1Score, self).__init__(name=name, **kwargs)\n",
        "        self.precision = Precision()\n",
        "        self.recall = Recall()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1c227107-a1b4-4f24-8729-35d581a3f310",
      "metadata": {
        "id": "1c227107-a1b4-4f24-8729-35d581a3f310"
      },
      "source": [
        "O próximo método é chamado durante o treinamento e a avaliação do modelo para atualizar o estado da métrica.  \n",
        "Ele recebe os valores verdadeiros (y_true) e preditos (y_pred), e, se necessário, os pesos amostrais (sample_weight). De modo que:\n",
        "\n",
        "**`self.precision.update_state(y_true, y_pred, sample_weight):`** Atualiza o cálculo da precisão com base nos valores verdadeiros e preditos.\n",
        "\n",
        "**`self.recall.update_state(y_true, y_pred, sample_weight):`** Atualiza o cálculo do recall com base nos valores verdadeiros e preditos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d35e2000-3760-46bc-97e7-2006186c7f54",
      "metadata": {
        "id": "d35e2000-3760-46bc-97e7-2006186c7f54",
        "tags": []
      },
      "outputs": [],
      "source": [
        "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
        "        self.precision.update_state(y_true, y_pred, sample_weight)\n",
        "        self.recall.update_state(y_true, y_pred, sample_weight)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e0f35509-af76-4df8-a14c-da95fc385596",
      "metadata": {
        "id": "e0f35509-af76-4df8-a14c-da95fc385596"
      },
      "source": [
        "Este método é chamado para calcular o valor da métrica (o F1-Score). Ele retorna o valor final da métrica com base nos valores de precisão e recall que foram atualizados. (A fórmula é uma média harmônica entre a precisão e o recall)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a1473b5-9d2b-42e5-b3d2-3db50d29ee78",
      "metadata": {
        "id": "8a1473b5-9d2b-42e5-b3d2-3db50d29ee78",
        "tags": []
      },
      "outputs": [],
      "source": [
        "    def result(self):\n",
        "        precision = self.precision.result()\n",
        "        recall = self.recall.result()\n",
        "        return 2 * ((precision * recall) / (precision + recall + tf.keras.backend.epsilon()))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b759459b-3edf-428c-820c-9d55a54f0059",
      "metadata": {
        "id": "b759459b-3edf-428c-820c-9d55a54f0059"
      },
      "source": [
        "O próximo método é chamado para resetar o estado das métricas de precisão e recall. Isso é necessário entre as épocas de treinamento ou quando desejamos limpar as estatísticas internas para um novo cálculo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "54c7c145-28b3-493b-9f71-49e91663fce0",
      "metadata": {
        "id": "54c7c145-28b3-493b-9f71-49e91663fce0",
        "tags": []
      },
      "outputs": [],
      "source": [
        "    def reset_states(self):\n",
        "        self.precision.reset_states()\n",
        "        self.recall.reset_states()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "y3kKOX3iJx4w",
      "metadata": {
        "id": "y3kKOX3iJx4w"
      },
      "source": [
        "# **Rede Neural Convolucional - CNN**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "09bfd8d0-7f7b-4813-b99f-797c063f3a30",
      "metadata": {
        "id": "09bfd8d0-7f7b-4813-b99f-797c063f3a30",
        "outputId": "34e8cc80-6212-4700-f604-09546c15b892",
        "tags": []
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.metrics import Precision, Recall\n",
        "from sklearn.metrics import f1_score\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import os\n",
        "\n",
        "# Explicação do problema\n",
        "# O objetivo deste modelo é classificar imagens de Pokémon utilizando uma Rede Neural Convolucional (CNN).\n",
        "# O dataset contém múltiplas classes, cada uma representando um Pokémon diferente. O modelo será treinado,\n",
        "# avaliado e testado para prever corretamente qual Pokémon está presente em cada imagem.\n",
        "\n",
        "\n",
        "# Parâmetros\n",
        "img_size = (128, 128)\n",
        "batch_size = 32\n",
        "\n",
        "# Pré-processamento das imagens\n",
        "train_datagen = ImageDataGenerator(rescale=1.0 / 255.0)\n",
        "val_datagen = ImageDataGenerator(rescale=1.0 / 255.0)\n",
        "test_datagen = ImageDataGenerator(rescale=1.0 / 255.0)\n",
        "\n",
        "# Criar os geradores de dados\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir, target_size=img_size, batch_size=batch_size, class_mode=\"categorical\"\n",
        ")\n",
        "val_generator = val_datagen.flow_from_directory(\n",
        "    val_dir, target_size=img_size, batch_size=batch_size, class_mode=\"categorical\"\n",
        ")\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir, target_size=img_size, batch_size=batch_size, class_mode=\"categorical\"\n",
        ")\n",
        "\n",
        "# Definir a métrica F1 personalizada\n",
        "class F1Score(tf.keras.metrics.Metric):\n",
        "    def __init__(self, name=\"f1_score\", **kwargs):\n",
        "        super(F1Score, self).__init__(name=name, **kwargs)\n",
        "        self.precision = Precision()\n",
        "        self.recall = Recall()\n",
        "\n",
        "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
        "        self.precision.update_state(y_true, y_pred, sample_weight)\n",
        "        self.recall.update_state(y_true, y_pred, sample_weight)\n",
        "\n",
        "    def result(self):\n",
        "        precision = self.precision.result()\n",
        "        recall = self.recall.result()\n",
        "        return 2 * ((precision * recall) / (precision + recall + tf.keras.backend.epsilon()))\n",
        "\n",
        "    def reset_states(self):\n",
        "        self.precision.reset_states()\n",
        "        self.recall.reset_states()\n",
        "\n",
        "# Criar a CNN\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(256, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(train_generator.num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "# Exibir arquitetura do modelo\n",
        "model.summary()\n",
        "\n",
        "# Compilar o modelo com as métricas de precisão, recall e F1Score\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy', Precision(), Recall(), F1Score()]\n",
        ")\n",
        "\n",
        "# Função para coletar as métricas durante o treinamento\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=val_generator,\n",
        "    epochs=5,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Avaliar o modelo no conjunto de teste\n",
        "loss, accuracy, precision, recall, f1_score_value = model.evaluate(test_generator)\n",
        "print(f'Loss no teste: {loss:.4f}, Acurácia no teste: {accuracy:.4f}, Precisão no teste: {precision:.4f}, Recall no teste: {recall:.4f}, F1-Score no teste: {f1_score_value:.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ac5378c4",
      "metadata": {
        "id": "ac5378c4"
      },
      "source": [
        "## 📌 Resumo das Camadas Iniciais da CNN\n",
        "\n",
        "### 🎯 Objetivo:\n",
        "Extrair características visuais\n",
        "\n",
        "---\n",
        "\n",
        "### 🔹 1. Camada: Convolução 2D\n",
        "📌 **Função:**  \n",
        "Detecta características espaciais nas imagens, detectando padrões locais.\n",
        "\n",
        "✅ **Parâmetros:**  \n",
        "| *Parâmetro*      | *Descrição* |\n",
        "|--------------------|--------------|\n",
        "| filters=32      | Define *32 filtros (ou kernels)* para detectar padrões na imagem (bordas, texturas, etc.). Cada filtro aprende uma característica diferente. |\n",
        "| kernel_size=(3,3) | O tamanho do *filtro deslizante* é *3x3 pixels*. Isso significa que ele analisa pequenos blocos da imagem por vez. |\n",
        "| activation='relu' | Usa a função de ativação *ReLU (Rectified Linear Unit)* para remover valores negativos e manter apenas os positivos. |\n",
        "| input_shape=(128, 128, 3) | Especifica o formato das imagens de entrada: *128x128 pixels, com 3 canais de cor (RGB)*. |\n",
        "\n",
        "**🎯 Saída:**\n",
        "Matriz com 32 canais contendo as \"versões filtradas\" da imagem.\n",
        "\n",
        "```python\n",
        "Conv2D()\n",
        "```\n",
        "\n",
        "### 🔹 2. Camada: MaxPooling\n",
        "\n",
        "📌 **Função:**\n",
        "Redução das dimensões da imagem, reduzindo cálculos e melhorando a eficiência, mantendo apenas os pontos importantes.\n",
        "Evita overfitting, pela redução da complexidade do modelo\n",
        "\n",
        "```python\n",
        "MaxPooling2D(pool_size=(2,2))\n",
        "```\n",
        "\n",
        "### 🔹 3. Camada: Segunda Convolução\n",
        "\n",
        "📌 **Função:**\n",
        "Como a imagem já foi reduzida antes pelo MaxPooling, agora os *filtros podem aprender padrões mais abstratos, como **formas completas (olhos, cauda, etc.)*.\n",
        "\n",
        "✅ **Parâmetros**\n",
        "| *Parâmetro*      | *Descrição* |\n",
        "|--------------------|--------------|\n",
        "| filters=64      | Agora a camada tem *64 filtros* para aprender *padrões mais complexos* (ex.: contornos e formatos). |\n",
        "| kernel_size=(3,3) | Continua analisando pedaços de *3x3 pixels* da imagem. |\n",
        "| activation='relu' | A função ReLU mantém apenas valores positivos. |\n",
        "\n",
        "\n",
        "```python\n",
        "Conv2D(filters=64, kernel_size=(3,3), activation='relu')\n",
        "```\n",
        "\n",
        "### 🔹 4. Camada: MaxPooling\n",
        "\n",
        "📌 **Função:**\n",
        "Como na sua utilização anterior, irá reduzir o tamanho da imagem pela metade\n",
        "\n",
        "```python\n",
        "MaxPooling2D(pool_size=(2,2))\n",
        "```\n",
        "\n",
        "### 🔹 5. Camada: Terceira Convolução\n",
        "\n",
        "📌 **Função:**\n",
        "Permitirá a rede reconhecer combinações de formas, no escopo do projeto, ela reconhecerá um pokémon inteiro, e não apenas seus contornos\n",
        "Quando mais camadas convolucionais, mas poder de abstração o modelo terá\n",
        "\n",
        "✅ **Parâmetros**\n",
        "| *Parâmetro*      | *Descrição* |\n",
        "|--------------------|--------------|\n",
        "| filters=128      | Agora temos *128 filtros, pois estamos aprendendo padrões **ainda mais complexos*. |\n",
        "| kernel_size=(3,3) | Mantemos um filtro pequeno para capturar detalhes. |\n",
        "| activation='relu' | Continua removendo valores negativos. |\n",
        "\n",
        "### 🔹 6. Camada: MaxPooling\n",
        "\n",
        "📌 **Função:**\n",
        "Reduz novamente o tamanho da imagem.\n",
        "Agora a rede foca apenas nas *informações mais importantes*.\n",
        "\n",
        "```python\n",
        "MaxPooling2D(pool_size=(2,2))\n",
        "```\n",
        "\n",
        "## 📌 Resumo Geral das Camadas Iniciais\n",
        "- Camada Convolucional extrai pequenos padrões da imagem.  \n",
        "- MaxPooling reduz a dimensão e mantém apenas os pontos mais importantes.  \n",
        "- Camada Convolucional aprende padrões mais abstratos.  \n",
        "- MaxPooling reduz mais a dimensão.  \n",
        "- Camada Convolucional aprende formas completas.  \n",
        "- MaxPooling mantém apenas as informações mais relevantes.  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c94d33f6",
      "metadata": {
        "id": "c94d33f6"
      },
      "source": [
        "## 📌 Resumo das Camadas Finais da CNN (A partir de Flatten)\n",
        "\n",
        "### 🎯 Objetivo:\n",
        "Após extrair características visuais, as camadas finais **combinam essas informações para realizar a classificação**.\n",
        "\n",
        "---\n",
        "\n",
        "### 🔹 1. Camada **Flatten (Achatamento)**\n",
        "📌 **Função:**  \n",
        "Transforma os mapas de características (matrizes 2D) em um **vetor 1D** para ser processado pelas camadas densas.\n",
        "\n",
        "✅ **Entrada:**  \n",
        "Matriz de características extraídas pelas camadas convolucionais (ex.: `8x8x128`).\n",
        "\n",
        "🎯 **Saída:**  \n",
        "Vetor linear (`8192`, se `8*8*128`).\n",
        "\n",
        "```python\n",
        "Flatten()\n",
        "```\n",
        "\n",
        "### 🔹 2. Camada Densa (256 Neurônios, ReLU)\n",
        "\n",
        "📌 **Função:**\n",
        "Combina as características extraídas para reconhecer padrões abstratos e tomar decisões.\n",
        "\n",
        "✅ **Parâmetros**\n",
        "\n",
        "    Dense(256, activation='relu')\n",
        "    256 neurônios aprendem padrões combinados.\n",
        "    ReLU impede valores negativos e melhora o treinamento.\n",
        "\n",
        "💡 **O que acontece aqui?**\n",
        "\n",
        "    \"Se há bordas pontiagudas e tom laranja predominante, é Charmander.\"\n",
        "    \"Se há orelhas arredondadas e tom amarelo, é Pikachu.\"\n",
        "\n",
        "```python\n",
        "Dense(256, activation='relu')\n",
        "```\n",
        "\n",
        "### 🔹 3. Camada Dropout (50%)\n",
        "\n",
        "📌 **Função:**\n",
        "Reduz overfitting desativando aleatoriamente 50% dos neurônios dessa camada a cada iteração.\n",
        "\n",
        "✅ **Parâmetros**\n",
        "\n",
        "    Dropout(0.5)\n",
        "\n",
        "🎯 **Benefício:**\n",
        "\n",
        "    ❌ Evita que o modelo fique muito dependente de neurônios específicos.\n",
        "    ✅ Melhora generalização para novas imagens.\n",
        "\n",
        "```python\n",
        "Dropout(0.5)\n",
        "```\n",
        "\n",
        "### 🔹 4. Camada Densa Final (Saída, Softmax)\n",
        "\n",
        "📌 **Função:**\n",
        "Gera as probabilidades para cada classe de Pokémon.\n",
        "\n",
        "✅ **Parâmetros**\n",
        "\n",
        "    Dense(num_classes, activation='softmax')\n",
        "    Número de neurônios = número de classes (ex.: 4 para Pikachu, Charmander, Bulbasaur e Squirtle).\n",
        "    Softmax converte valores em probabilidades.\n",
        "\n",
        "🎯 **Exemplo de saída:**\n",
        "\n",
        "[Pikachu: 0.80, Charmander: 0.15, Bulbasaur: 0.03, Squirtle: 0.02]\n",
        "\n",
        "➡ Resposta final: Pikachu! ✅\n",
        "\n",
        "```python\n",
        "Dense(num_classes, activation='softmax')\n",
        "```\n",
        "\n",
        "## 📌 Resumo Geral das Camadas\n",
        "- Camada\tFunção Principal\tDetalhes\n",
        "- Flatten\tTransforma mapas de características em um vetor 1D.\tEntrada: matriz → Saída: vetor\n",
        "- Dense (256, ReLU)\tAprende relações complexas entre padrões extraídos.\t256 neurônios totalmente conectados.\n",
        "- Dropout (50%)\tPrevine overfitting desativando neurônios aleatoriamente.\tEvita que o modelo memorize o conjunto de treino.\n",
        "- Dense (Softmax)\tGera as probabilidades de cada classe.\tNúmero de neurônios = número de classes."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "-PqJ9vZ6K799",
      "metadata": {
        "id": "-PqJ9vZ6K799"
      },
      "source": [
        "# **Visualização**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ec85caa-49f5-4226-86bb-5d0599d39fb6",
      "metadata": {
        "id": "7ec85caa-49f5-4226-86bb-5d0599d39fb6",
        "outputId": "ab9e62f0-a5a6-42eb-b006-634e43516956"
      },
      "outputs": [],
      "source": [
        "# Mostrar algumas imagens de teste com rótulos reais e preditos\n",
        "class_names = list(train_generator.class_indices.keys())\n",
        "images, labels = next(test_generator)\n",
        "predictions = model.predict(images)\n",
        "pred_labels = np.argmax(predictions, axis=1)\n",
        "\n",
        "num_images = min(len(images), 5)\n",
        "\n",
        "fig, axes = plt.subplots(1, num_images, figsize=(10, 3))\n",
        "for i in range(num_images):\n",
        "    axes[i].imshow(images[i])\n",
        "    true_label = class_names[np.argmax(labels[i])]\n",
        "    predicted_label = class_names[pred_labels[i]]\n",
        "    color = \"green\" if true_label == predicted_label else \"red\"\n",
        "    axes[i].set_title(f\"Real: {true_label}\\nPred: {predicted_label}\", color=color)\n",
        "    axes[i].axis(\"off\")\n",
        "plt.show()\n",
        "\n",
        "# Plotar as curvas das métricas\n",
        "plt.figure(figsize=(15, 3))\n",
        "\n",
        "# Acurácia\n",
        "plt.subplot(1, 4, 1)\n",
        "plt.plot(history.history['accuracy'], label='Acurácia Treino')\n",
        "plt.plot(history.history['val_accuracy'], label='Acurácia Validação')\n",
        "plt.xlabel('Épocas')\n",
        "plt.ylabel('Acurácia')\n",
        "plt.legend()\n",
        "plt.title('Acurácia por Época')\n",
        "\n",
        "# Precisão\n",
        "plt.subplot(1, 4, 2)\n",
        "plt.plot(history.history['precision'], label='Precisão Treino')\n",
        "plt.plot(history.history['val_precision'], label='Precisão Validação')\n",
        "plt.xlabel('Épocas')\n",
        "plt.ylabel('Precisão')\n",
        "plt.legend()\n",
        "plt.title('Precisão por Época')\n",
        "\n",
        "# Recall\n",
        "plt.subplot(1, 4, 3)\n",
        "plt.plot(history.history['recall'], label='Recall Treino')\n",
        "plt.plot(history.history['val_recall'], label='Recall Validação')\n",
        "plt.xlabel('Épocas')\n",
        "plt.ylabel('Recall')\n",
        "plt.legend()\n",
        "plt.title('Recall por Época')\n",
        "\n",
        "# F1-Score\n",
        "plt.subplot(1, 4, 4)\n",
        "plt.plot(history.history['f1_score'], label='F1-Score Treino')\n",
        "plt.plot(history.history['val_f1_score'], label='F1-Score Validação')\n",
        "plt.xlabel('Épocas')\n",
        "plt.ylabel('F1-Score')\n",
        "plt.legend()\n",
        "plt.title('F1-Score por Época')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "716e8748",
      "metadata": {
        "id": "716e8748"
      },
      "source": [
        "No contexto do treinamento de modelos de machine learning, especialmente em classificação, acurácia e precisão são métricas diferentes que avaliam diferentes aspectos do desempenho do modelo.\n",
        "\n",
        "Acurácia: Proporção de previsões corretas (tanto verdadeiros positivos quanto verdadeiros negativos) em relação ao total de previsões feitas. É uma métrica geral que indica a porcentagem de previsões corretas feitas pelo modelo.\n",
        "\n",
        "        Acurácia = (Verdadeiros positivos + Verdadeiros negativos) / Total de previsões\n",
        "\n",
        "\n",
        "Precisão: A proporção de verdadeiros positivos em relação ao total de previsões positivas feitas pelo modelo. Mede a exatidão das previsões positivas do modelo. É particularmente útil quando o custo de falsos positivos é alto.\n",
        "\n",
        "        Precisão = Verdadeiros Positivos / (Verdadeiros Positivos + Falsos Positivos)\n",
        "\n",
        "\n",
        "Recall: É a proporção de verdadeiros positivos em relação ao total de positivos reais (verdadeiros positivos + falsos negativos). Mede a capacidade do modelo de identificar corretamente todas as instâncias positivas.\n",
        "\n",
        "        Recall = Verdadeiros Positivos / (Verdadeiros Positivos + Falsos Negativos)\n",
        "\n",
        "F1-Score: É a média harmônica da precisão e do recall. O F1-score é uma métrica útil quando se precisa equilibrar precisão e recall, especialmente em situações onde há uma distribuição desigual das classes.\n",
        "\n",
        "        F1-Score = 2 x (Precisão x Recall) / (Precisão + Recall)\n",
        "\n",
        "\n",
        "Isso permite uma avaliação completa do desempenho do modelo, considerando diferentes aspectos importantes para a tarefa de classificação.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
