{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "uEmwiyXsI3zz",
      "metadata": {
        "id": "uEmwiyXsI3zz"
      },
      "source": [
        "# **Trabalho Final - Intelig√™ncia Artificial - Classifica√ß√£o de Pok√©mon**\n",
        "\n",
        "*Equipe:*\n",
        "- Anna Beatriz - 538758\n",
        "- Kauan Soares - 537063\n",
        "- Leonan Marques - 539000\n",
        "- Victoria Moura - 541801\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "_RSWETr5Jaaz",
      "metadata": {
        "id": "_RSWETr5Jaaz"
      },
      "source": [
        "# **Contextualiza√ß√£o e Conceitos Utilizados**\n",
        "\n",
        "\n",
        "\n",
        "A proposta principal do nosso trabalho √© criar um modelo de I.A que seja capaz de identificar qual Pokem√≥n aparece em cada imagem dentre um conjunto de imagens. Para isso, utilizamos uma abordagem baseada em Redes Neurais Convolucionais (CNNs), que s√£o amplamente usadas para an√°lise e reconhecimento de imagens.\n",
        "\n",
        "No entanto, para que a CNN consiga aprender a distinguir cada Pok√©mon corretamente, faremos uso de aprendizado supervisionado. Isso significa que fornecemos ao modelo imagens j√° rotuladas, indicando a qual Pok√©mon cada uma pertence, e o modelo aprende, com base nesses exemplos, a fazer suas pr√≥prias previs√µes.\n",
        "\n",
        "No nosso projeto, estruturamos a CNN com camadas especializadas:\n",
        "-  Camadas *Convolucionais*, que identificam padr√µes locais nas imagens, como contornos e cores distintas.\n",
        "- Camadas de *Pooling*, que reduzem a dimensionalidade da imagem, tornando o modelo mais eficiente.\n",
        "- Camadas *Densas*, que combinam as informa√ß√µes extra√≠das e fazem a predi√ß√£o final do Pok√©mon.\n",
        "\n",
        "Essa arquitetura permite que o modelo aprenda progressivamente a reconhecer caracter√≠sticas espec√≠ficas de cada Pok√©mon e utilize essas informa√ß√µes para classific√°-los corretamente."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "LXLMoHL2JfnC",
      "metadata": {
        "id": "LXLMoHL2JfnC"
      },
      "source": [
        "# **Imports e inicializa√ß√£o**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f219de6",
      "metadata": {
        "id": "1f219de6",
        "outputId": "66f7552e-d7ab-4f49-a2aa-f119636e7c48"
      },
      "outputs": [],
      "source": [
        "%pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "356bc245-c7d7-4224-aca4-7da5e4da390a",
      "metadata": {
        "id": "356bc245-c7d7-4224-aca4-7da5e4da390a",
        "tags": []
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.metrics import Precision, Recall\n",
        "from sklearn.metrics import f1_score\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fU43sCa4JkQ6",
      "metadata": {
        "id": "fU43sCa4JkQ6"
      },
      "source": [
        "# **Tratamento dos dados**\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "897cd255-25a8-4596-a1b0-6ea381814818",
      "metadata": {
        "id": "897cd255-25a8-4596-a1b0-6ea381814818"
      },
      "source": [
        "O dataset traz um c√≥digo que ja divide as imagens em 80% treino, 10% valida√ß√£o e 10% teste"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "150eb47b-d821-42ca-b782-a0345ae1fa44",
      "metadata": {
        "id": "150eb47b-d821-42ca-b782-a0345ae1fa44",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Definir diret√≥rios dos conjuntos de imagens\n",
        "train_dir = \"./pokemon-dataset-1000 - Copia/train\"\n",
        "val_dir = \"./pokemon-dataset-1000 - Copia/val\"\n",
        "test_dir = \"./pokemon-dataset-1000 - Copia/test\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "522f8aa7-38f3-4e8e-ae4b-cd68eac15224",
      "metadata": {
        "id": "522f8aa7-38f3-4e8e-ae4b-cd68eac15224"
      },
      "source": [
        "**`train_dir`**: Conjunto de imagens usado para treinar o modelo.\n",
        "\n",
        "**`val_dir`**: Conjunto de imagens usado para validar o modelo durante o treinamento.\n",
        "\n",
        "**`test_dir`**: Conjunto de imagens usado para avaliar o desempenho do modelo ap√≥s o treinamento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c4a40eed-4c41-4b87-a054-bb63de6334c4",
      "metadata": {
        "id": "c4a40eed-4c41-4b87-a054-bb63de6334c4",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Par√¢metros\n",
        "img_size = (128, 128)\n",
        "batch_size = 32"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "29884af8-2390-401e-a7f5-e4e31f666404",
      "metadata": {
        "id": "29884af8-2390-401e-a7f5-e4e31f666404"
      },
      "source": [
        "**`img_size`** : Define o tamanho de cada imagem que ser√° alimentada ao modelo. Como o modelo de CNN est√° criando est√° lidando com imagens, √© necess√°rio garantir que todas as imagens sejam redimensionadas para um tamanho comum antes de serem passadas para a rede.  \n",
        "\n",
        "**`batch_size`** : Define o n√∫mero de imagens que ser√£o passadas pela rede neural em uma √∫nica itera√ß√£o durante o treinamento.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3890bddf-8eba-4891-a90a-448b4871a8af",
      "metadata": {
        "id": "3890bddf-8eba-4891-a90a-448b4871a8af",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Pr√©-processamento das imagens\n",
        "train_datagen = ImageDataGenerator(rescale=1.0 / 255.0)\n",
        "val_datagen = ImageDataGenerator(rescale=1.0 / 255.0)\n",
        "test_datagen = ImageDataGenerator(rescale=1.0 / 255.0)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fcf53ce8-21f7-4e63-90ec-1a958934be8a",
      "metadata": {
        "id": "fcf53ce8-21f7-4e63-90ec-1a958934be8a"
      },
      "source": [
        "**OBS:** A normaliza√ß√£o ajuda a acelerar o processo de treinamento, pois pode reduzir a variabilidade nos gradientes e melhorar a converg√™ncia. Tamb√©m pode ajudar o modelo a se ajustar de maneira mais eficiente aos dados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f8662ea-ce09-44f5-b259-3fc64a436c04",
      "metadata": {
        "id": "0f8662ea-ce09-44f5-b259-3fc64a436c04",
        "outputId": "55c31ec6-7311-4e89-842c-214ed192de61",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Criar os geradores de dados (Treino, Teste e Valida√ß√£o)\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir, target_size=img_size, batch_size=batch_size, class_mode=\"categorical\"\n",
        ")\n",
        "val_generator = val_datagen.flow_from_directory(\n",
        "    val_dir, target_size=img_size, batch_size=batch_size, class_mode=\"categorical\"\n",
        ")\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir, target_size=img_size, batch_size=batch_size, class_mode=\"categorical\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9477b8fe",
      "metadata": {
        "id": "9477b8fe"
      },
      "source": [
        "**`train_datagen:`** Este √© o objeto de pr√©-processamento que foi configurado anteriormente (com a normaliza√ß√£o dos pixels e, possivelmente, aumentos de dados, caso tenha sido configurado).  \n",
        "\n",
        "**`flow_from_directory(train_dir):`** Este m√©todo cria um gerador que ir√° buscar as imagens no diret√≥rio train_dir (diret√≥rio que cont√©m as imagens de treinamento). As imagens devem estar organizadas em subpastas, onde cada subpasta representa uma classe. O nome da subpasta ser√° usado como o r√≥tulo da classe.  \n",
        "\n",
        "**`class_mode=\"categorical\":`** Como estamos tratando um problema de classifica√ß√£o multiclasse, este par√¢metro indica que as labels (r√≥tulos) ser√£o codificadas de forma categ√≥rica. Ou seja, para cada imagem, a sa√≠da ser√° um vetor \"one-hot\" representando a classe da imagem."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af669c16-d1b7-4999-817c-f4ac07da53dd",
      "metadata": {
        "id": "af669c16-d1b7-4999-817c-f4ac07da53dd",
        "outputId": "dc1dc7bd-b7f1-4033-86b4-fd579af08122",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Visualizar 5 exemplos do conjunto de treino\n",
        "class_names = list(train_generator.class_indices.keys())\n",
        "num_examples = 5\n",
        "\n",
        "fig, axes = plt.subplots(1, num_examples, figsize=(15, 5))\n",
        "train_images, train_labels = next(train_generator)\n",
        "\n",
        "for i in range(num_examples):\n",
        "    img = train_images[i]\n",
        "    axes[i].imshow(img)\n",
        "    axes[i].set_title(f\"Classe: {class_names[np.argmax(train_labels[i])]} \")\n",
        "    axes[i].axis(\"off\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3878f4be-76ff-42ad-ada1-d787d04acd69",
      "metadata": {
        "id": "3878f4be-76ff-42ad-ada1-d787d04acd69"
      },
      "source": [
        "A classe F1Score herda de tf.keras.metrics.Metric, o que permite criar m√©tricas personalizadas para serem usadas com o TensorFlow/Keras.  \n",
        "Definimos duas m√©tricas auxiliares: Precision e Recall (essas duas m√©tricas ser√£o usadas para calcular o F1-Score.)  \n",
        "\n",
        "**OBS**: `Precision` mede a propor√ß√£o de predi√ß√µes positivas corretas, e `recall` mede a propor√ß√£o de inst√¢ncias positivas que foram corretamente identificadas, ou seja, quantas das inst√¢ncias reais positivas foram capturadas pelo modelo.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a663584-76fd-4711-a517-eaa49e7fbb53",
      "metadata": {
        "id": "5a663584-76fd-4711-a517-eaa49e7fbb53",
        "tags": []
      },
      "outputs": [],
      "source": [
        "class F1Score(tf.keras.metrics.Metric):\n",
        "    def __init__(self, name=\"f1_score\", **kwargs):\n",
        "        super(F1Score, self).__init__(name=name, **kwargs)\n",
        "        self.precision = Precision()\n",
        "        self.recall = Recall()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1c227107-a1b4-4f24-8729-35d581a3f310",
      "metadata": {
        "id": "1c227107-a1b4-4f24-8729-35d581a3f310"
      },
      "source": [
        "O pr√≥ximo m√©todo √© chamado durante o treinamento e a avalia√ß√£o do modelo para atualizar o estado da m√©trica.  \n",
        "Ele recebe os valores verdadeiros (y_true) e preditos (y_pred), e, se necess√°rio, os pesos amostrais (sample_weight). De modo que:\n",
        "\n",
        "**`self.precision.update_state(y_true, y_pred, sample_weight):`** Atualiza o c√°lculo da precis√£o com base nos valores verdadeiros e preditos.\n",
        "\n",
        "**`self.recall.update_state(y_true, y_pred, sample_weight):`** Atualiza o c√°lculo do recall com base nos valores verdadeiros e preditos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d35e2000-3760-46bc-97e7-2006186c7f54",
      "metadata": {
        "id": "d35e2000-3760-46bc-97e7-2006186c7f54",
        "tags": []
      },
      "outputs": [],
      "source": [
        "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
        "        self.precision.update_state(y_true, y_pred, sample_weight)\n",
        "        self.recall.update_state(y_true, y_pred, sample_weight)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e0f35509-af76-4df8-a14c-da95fc385596",
      "metadata": {
        "id": "e0f35509-af76-4df8-a14c-da95fc385596"
      },
      "source": [
        "Este m√©todo √© chamado para calcular o valor da m√©trica (o F1-Score). Ele retorna o valor final da m√©trica com base nos valores de precis√£o e recall que foram atualizados. (A f√≥rmula √© uma m√©dia harm√¥nica entre a precis√£o e o recall)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a1473b5-9d2b-42e5-b3d2-3db50d29ee78",
      "metadata": {
        "id": "8a1473b5-9d2b-42e5-b3d2-3db50d29ee78",
        "tags": []
      },
      "outputs": [],
      "source": [
        "    def result(self):\n",
        "        precision = self.precision.result()\n",
        "        recall = self.recall.result()\n",
        "        return 2 * ((precision * recall) / (precision + recall + tf.keras.backend.epsilon()))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b759459b-3edf-428c-820c-9d55a54f0059",
      "metadata": {
        "id": "b759459b-3edf-428c-820c-9d55a54f0059"
      },
      "source": [
        "O pr√≥ximo m√©todo √© chamado para resetar o estado das m√©tricas de precis√£o e recall. Isso √© necess√°rio entre as √©pocas de treinamento ou quando desejamos limpar as estat√≠sticas internas para um novo c√°lculo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "54c7c145-28b3-493b-9f71-49e91663fce0",
      "metadata": {
        "id": "54c7c145-28b3-493b-9f71-49e91663fce0",
        "tags": []
      },
      "outputs": [],
      "source": [
        "    def reset_states(self):\n",
        "        self.precision.reset_states()\n",
        "        self.recall.reset_states()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "y3kKOX3iJx4w",
      "metadata": {
        "id": "y3kKOX3iJx4w"
      },
      "source": [
        "# **Rede Neural Convolucional - CNN**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "09bfd8d0-7f7b-4813-b99f-797c063f3a30",
      "metadata": {
        "id": "09bfd8d0-7f7b-4813-b99f-797c063f3a30",
        "outputId": "34e8cc80-6212-4700-f604-09546c15b892",
        "tags": []
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.metrics import Precision, Recall\n",
        "from sklearn.metrics import f1_score\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import os\n",
        "\n",
        "# Explica√ß√£o do problema\n",
        "# O objetivo deste modelo √© classificar imagens de Pok√©mon utilizando uma Rede Neural Convolucional (CNN).\n",
        "# O dataset cont√©m m√∫ltiplas classes, cada uma representando um Pok√©mon diferente. O modelo ser√° treinado,\n",
        "# avaliado e testado para prever corretamente qual Pok√©mon est√° presente em cada imagem.\n",
        "\n",
        "\n",
        "# Par√¢metros\n",
        "img_size = (128, 128)\n",
        "batch_size = 32\n",
        "\n",
        "# Pr√©-processamento das imagens\n",
        "train_datagen = ImageDataGenerator(rescale=1.0 / 255.0)\n",
        "val_datagen = ImageDataGenerator(rescale=1.0 / 255.0)\n",
        "test_datagen = ImageDataGenerator(rescale=1.0 / 255.0)\n",
        "\n",
        "# Criar os geradores de dados\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir, target_size=img_size, batch_size=batch_size, class_mode=\"categorical\"\n",
        ")\n",
        "val_generator = val_datagen.flow_from_directory(\n",
        "    val_dir, target_size=img_size, batch_size=batch_size, class_mode=\"categorical\"\n",
        ")\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir, target_size=img_size, batch_size=batch_size, class_mode=\"categorical\"\n",
        ")\n",
        "\n",
        "# Definir a m√©trica F1 personalizada\n",
        "class F1Score(tf.keras.metrics.Metric):\n",
        "    def __init__(self, name=\"f1_score\", **kwargs):\n",
        "        super(F1Score, self).__init__(name=name, **kwargs)\n",
        "        self.precision = Precision()\n",
        "        self.recall = Recall()\n",
        "\n",
        "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
        "        self.precision.update_state(y_true, y_pred, sample_weight)\n",
        "        self.recall.update_state(y_true, y_pred, sample_weight)\n",
        "\n",
        "    def result(self):\n",
        "        precision = self.precision.result()\n",
        "        recall = self.recall.result()\n",
        "        return 2 * ((precision * recall) / (precision + recall + tf.keras.backend.epsilon()))\n",
        "\n",
        "    def reset_states(self):\n",
        "        self.precision.reset_states()\n",
        "        self.recall.reset_states()\n",
        "\n",
        "# Criar a CNN\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(256, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(train_generator.num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "# Exibir arquitetura do modelo\n",
        "model.summary()\n",
        "\n",
        "# Compilar o modelo com as m√©tricas de precis√£o, recall e F1Score\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy', Precision(), Recall(), F1Score()]\n",
        ")\n",
        "\n",
        "# Fun√ß√£o para coletar as m√©tricas durante o treinamento\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=val_generator,\n",
        "    epochs=5,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Avaliar o modelo no conjunto de teste\n",
        "loss, accuracy, precision, recall, f1_score_value = model.evaluate(test_generator)\n",
        "print(f'Loss no teste: {loss:.4f}, Acur√°cia no teste: {accuracy:.4f}, Precis√£o no teste: {precision:.4f}, Recall no teste: {recall:.4f}, F1-Score no teste: {f1_score_value:.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ac5378c4",
      "metadata": {
        "id": "ac5378c4"
      },
      "source": [
        "## üìå Resumo das Camadas Iniciais da CNN\n",
        "\n",
        "### üéØ Objetivo:\n",
        "Extrair caracter√≠sticas visuais\n",
        "\n",
        "---\n",
        "\n",
        "### üîπ 1. Camada: Convolu√ß√£o 2D\n",
        "üìå **Fun√ß√£o:**  \n",
        "Detecta caracter√≠sticas espaciais nas imagens, detectando padr√µes locais.\n",
        "\n",
        "‚úÖ **Par√¢metros:**  \n",
        "| *ParaÃÇmetro*      | *DescricÃßaÃÉo* |\n",
        "|--------------------|--------------|\n",
        "| filters=32      | Define *32 filtros (ou kernels)* para detectar padroÃÉes na imagem (bordas, texturas, etc.). Cada filtro aprende uma caracteriÃÅstica diferente. |\n",
        "| kernel_size=(3,3) | O tamanho do *filtro deslizante* eÃÅ *3x3 pixels*. Isso significa que ele analisa pequenos blocos da imagem por vez. |\n",
        "| activation='relu' | Usa a funcÃßaÃÉo de ativacÃßaÃÉo *ReLU (Rectified Linear Unit)* para remover valores negativos e manter apenas os positivos. |\n",
        "| input_shape=(128, 128, 3) | Especifica o formato das imagens de entrada: *128x128 pixels, com 3 canais de cor (RGB)*. |\n",
        "\n",
        "**üéØ Sa√≠da:**\n",
        "Matriz com 32 canais contendo as \"versoÃÉes filtradas\" da imagem.\n",
        "\n",
        "```python\n",
        "Conv2D()\n",
        "```\n",
        "\n",
        "### üîπ 2. Camada: MaxPooling\n",
        "\n",
        "üìå **Fun√ß√£o:**\n",
        "Redu√ß√£o das dimens√µes da imagem, reduzindo c√°lculos e melhorando a efici√™ncia, mantendo apenas os pontos importantes.\n",
        "Evita overfitting, pela redu√ß√£o da complexidade do modelo\n",
        "\n",
        "```python\n",
        "MaxPooling2D(pool_size=(2,2))\n",
        "```\n",
        "\n",
        "### üîπ 3. Camada: Segunda ConvolucÃßaÃÉo\n",
        "\n",
        "üìå **Fun√ß√£o:**\n",
        "Como a imagem jaÃÅ foi reduzida antes pelo MaxPooling, agora os *filtros podem aprender padroÃÉes mais abstratos, como **formas completas (olhos, cauda, etc.)*.\n",
        "\n",
        "‚úÖ **Par√¢metros**\n",
        "| *ParaÃÇmetro*      | *DescricÃßaÃÉo* |\n",
        "|--------------------|--------------|\n",
        "| filters=64      | Agora a camada tem *64 filtros* para aprender *padroÃÉes mais complexos* (ex.: contornos e formatos). |\n",
        "| kernel_size=(3,3) | Continua analisando pedacÃßos de *3x3 pixels* da imagem. |\n",
        "| activation='relu' | A funcÃßaÃÉo ReLU manteÃÅm apenas valores positivos. |\n",
        "\n",
        "\n",
        "```python\n",
        "Conv2D(filters=64, kernel_size=(3,3), activation='relu')\n",
        "```\n",
        "\n",
        "### üîπ 4. Camada: MaxPooling\n",
        "\n",
        "üìå **Fun√ß√£o:**\n",
        "Como na sua utiliza√ß√£o anterior, ir√° reduzir o tamanho da imagem pela metade\n",
        "\n",
        "```python\n",
        "MaxPooling2D(pool_size=(2,2))\n",
        "```\n",
        "\n",
        "### üîπ 5. Camada: Terceira ConvolucÃßaÃÉo\n",
        "\n",
        "üìå **Fun√ß√£o:**\n",
        "Permitir√° a rede reconhecer combina√ß√µes de formas, no escopo do projeto, ela reconhecer√° um pok√©mon inteiro, e n√£o apenas seus contornos\n",
        "Quando mais camadas convolucionais, mas poder de abstra√ß√£o o modelo ter√°\n",
        "\n",
        "‚úÖ **Par√¢metros**\n",
        "| *ParaÃÇmetro*      | *DescricÃßaÃÉo* |\n",
        "|--------------------|--------------|\n",
        "| filters=128      | Agora temos *128 filtros, pois estamos aprendendo padroÃÉes **ainda mais complexos*. |\n",
        "| kernel_size=(3,3) | Mantemos um filtro pequeno para capturar detalhes. |\n",
        "| activation='relu' | Continua removendo valores negativos. |\n",
        "\n",
        "### üîπ 6. Camada: MaxPooling\n",
        "\n",
        "üìå **Fun√ß√£o:**\n",
        "Reduz novamente o tamanho da imagem.\n",
        "Agora a rede foca apenas nas *informacÃßoÃÉes mais importantes*.\n",
        "\n",
        "```python\n",
        "MaxPooling2D(pool_size=(2,2))\n",
        "```\n",
        "\n",
        "## üìå Resumo Geral das Camadas Iniciais\n",
        "- Camada Convolucional extrai pequenos padroÃÉes da imagem.  \n",
        "- MaxPooling reduz a dimensaÃÉo e manteÃÅm apenas os pontos mais importantes.  \n",
        "- Camada Convolucional aprende padroÃÉes mais abstratos.  \n",
        "- MaxPooling reduz mais a dimensaÃÉo.  \n",
        "- Camada Convolucional aprende formas completas.  \n",
        "- MaxPooling manteÃÅm apenas as informacÃßoÃÉes mais relevantes.  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c94d33f6",
      "metadata": {
        "id": "c94d33f6"
      },
      "source": [
        "## üìå Resumo das Camadas Finais da CNN (A partir de Flatten)\n",
        "\n",
        "### üéØ Objetivo:\n",
        "Ap√≥s extrair caracter√≠sticas visuais, as camadas finais **combinam essas informa√ß√µes para realizar a classifica√ß√£o**.\n",
        "\n",
        "---\n",
        "\n",
        "### üîπ 1. Camada **Flatten (Achatamento)**\n",
        "üìå **Fun√ß√£o:**  \n",
        "Transforma os mapas de caracter√≠sticas (matrizes 2D) em um **vetor 1D** para ser processado pelas camadas densas.\n",
        "\n",
        "‚úÖ **Entrada:**  \n",
        "Matriz de caracter√≠sticas extra√≠das pelas camadas convolucionais (ex.: `8x8x128`).\n",
        "\n",
        "üéØ **Sa√≠da:**  \n",
        "Vetor linear (`8192`, se `8*8*128`).\n",
        "\n",
        "```python\n",
        "Flatten()\n",
        "```\n",
        "\n",
        "### üîπ 2. Camada Densa (256 Neur√¥nios, ReLU)\n",
        "\n",
        "üìå **Fun√ß√£o:**\n",
        "Combina as caracter√≠sticas extra√≠das para reconhecer padr√µes abstratos e tomar decis√µes.\n",
        "\n",
        "‚úÖ **Par√¢metros**\n",
        "\n",
        "    Dense(256, activation='relu')\n",
        "    256 neur√¥nios aprendem padr√µes combinados.\n",
        "    ReLU impede valores negativos e melhora o treinamento.\n",
        "\n",
        "üí° **O que acontece aqui?**\n",
        "\n",
        "    \"Se h√° bordas pontiagudas e tom laranja predominante, √© Charmander.\"\n",
        "    \"Se h√° orelhas arredondadas e tom amarelo, √© Pikachu.\"\n",
        "\n",
        "```python\n",
        "Dense(256, activation='relu')\n",
        "```\n",
        "\n",
        "### üîπ 3. Camada Dropout (50%)\n",
        "\n",
        "üìå **Fun√ß√£o:**\n",
        "Reduz overfitting desativando aleatoriamente 50% dos neur√¥nios dessa camada a cada itera√ß√£o.\n",
        "\n",
        "‚úÖ **Par√¢metros**\n",
        "\n",
        "    Dropout(0.5)\n",
        "\n",
        "üéØ **Benef√≠cio:**\n",
        "\n",
        "    ‚ùå Evita que o modelo fique muito dependente de neur√¥nios espec√≠ficos.\n",
        "    ‚úÖ Melhora generaliza√ß√£o para novas imagens.\n",
        "\n",
        "```python\n",
        "Dropout(0.5)\n",
        "```\n",
        "\n",
        "### üîπ 4. Camada Densa Final (Sa√≠da, Softmax)\n",
        "\n",
        "üìå **Fun√ß√£o:**\n",
        "Gera as probabilidades para cada classe de Pok√©mon.\n",
        "\n",
        "‚úÖ **Par√¢metros**\n",
        "\n",
        "    Dense(num_classes, activation='softmax')\n",
        "    N√∫mero de neur√¥nios = n√∫mero de classes (ex.: 4 para Pikachu, Charmander, Bulbasaur e Squirtle).\n",
        "    Softmax converte valores em probabilidades.\n",
        "\n",
        "üéØ **Exemplo de sa√≠da:**\n",
        "\n",
        "[Pikachu: 0.80, Charmander: 0.15, Bulbasaur: 0.03, Squirtle: 0.02]\n",
        "\n",
        "‚û° Resposta final: Pikachu! ‚úÖ\n",
        "\n",
        "```python\n",
        "Dense(num_classes, activation='softmax')\n",
        "```\n",
        "\n",
        "## üìå Resumo Geral das Camadas\n",
        "- Camada\tFun√ß√£o Principal\tDetalhes\n",
        "- Flatten\tTransforma mapas de caracter√≠sticas em um vetor 1D.\tEntrada: matriz ‚Üí Sa√≠da: vetor\n",
        "- Dense (256, ReLU)\tAprende rela√ß√µes complexas entre padr√µes extra√≠dos.\t256 neur√¥nios totalmente conectados.\n",
        "- Dropout (50%)\tPrevine overfitting desativando neur√¥nios aleatoriamente.\tEvita que o modelo memorize o conjunto de treino.\n",
        "- Dense (Softmax)\tGera as probabilidades de cada classe.\tN√∫mero de neur√¥nios = n√∫mero de classes."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "-PqJ9vZ6K799",
      "metadata": {
        "id": "-PqJ9vZ6K799"
      },
      "source": [
        "# **Visualiza√ß√£o**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ec85caa-49f5-4226-86bb-5d0599d39fb6",
      "metadata": {
        "id": "7ec85caa-49f5-4226-86bb-5d0599d39fb6",
        "outputId": "ab9e62f0-a5a6-42eb-b006-634e43516956"
      },
      "outputs": [],
      "source": [
        "# Mostrar algumas imagens de teste com r√≥tulos reais e preditos\n",
        "class_names = list(train_generator.class_indices.keys())\n",
        "images, labels = next(test_generator)\n",
        "predictions = model.predict(images)\n",
        "pred_labels = np.argmax(predictions, axis=1)\n",
        "\n",
        "num_images = min(len(images), 5)\n",
        "\n",
        "fig, axes = plt.subplots(1, num_images, figsize=(10, 3))\n",
        "for i in range(num_images):\n",
        "    axes[i].imshow(images[i])\n",
        "    true_label = class_names[np.argmax(labels[i])]\n",
        "    predicted_label = class_names[pred_labels[i]]\n",
        "    color = \"green\" if true_label == predicted_label else \"red\"\n",
        "    axes[i].set_title(f\"Real: {true_label}\\nPred: {predicted_label}\", color=color)\n",
        "    axes[i].axis(\"off\")\n",
        "plt.show()\n",
        "\n",
        "# Plotar as curvas das m√©tricas\n",
        "plt.figure(figsize=(15, 3))\n",
        "\n",
        "# Acur√°cia\n",
        "plt.subplot(1, 4, 1)\n",
        "plt.plot(history.history['accuracy'], label='Acur√°cia Treino')\n",
        "plt.plot(history.history['val_accuracy'], label='Acur√°cia Valida√ß√£o')\n",
        "plt.xlabel('√âpocas')\n",
        "plt.ylabel('Acur√°cia')\n",
        "plt.legend()\n",
        "plt.title('Acur√°cia por √âpoca')\n",
        "\n",
        "# Precis√£o\n",
        "plt.subplot(1, 4, 2)\n",
        "plt.plot(history.history['precision'], label='Precis√£o Treino')\n",
        "plt.plot(history.history['val_precision'], label='Precis√£o Valida√ß√£o')\n",
        "plt.xlabel('√âpocas')\n",
        "plt.ylabel('Precis√£o')\n",
        "plt.legend()\n",
        "plt.title('Precis√£o por √âpoca')\n",
        "\n",
        "# Recall\n",
        "plt.subplot(1, 4, 3)\n",
        "plt.plot(history.history['recall'], label='Recall Treino')\n",
        "plt.plot(history.history['val_recall'], label='Recall Valida√ß√£o')\n",
        "plt.xlabel('√âpocas')\n",
        "plt.ylabel('Recall')\n",
        "plt.legend()\n",
        "plt.title('Recall por √âpoca')\n",
        "\n",
        "# F1-Score\n",
        "plt.subplot(1, 4, 4)\n",
        "plt.plot(history.history['f1_score'], label='F1-Score Treino')\n",
        "plt.plot(history.history['val_f1_score'], label='F1-Score Valida√ß√£o')\n",
        "plt.xlabel('√âpocas')\n",
        "plt.ylabel('F1-Score')\n",
        "plt.legend()\n",
        "plt.title('F1-Score por √âpoca')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "716e8748",
      "metadata": {
        "id": "716e8748"
      },
      "source": [
        "No contexto do treinamento de modelos de machine learning, especialmente em classificacÃßaÃÉo, acuraÃÅcia e precisaÃÉo saÃÉo meÃÅtricas diferentes que avaliam diferentes aspectos do desempenho do modelo.\n",
        "\n",
        "AcuraÃÅcia: ProporcÃßaÃÉo de previsoÃÉes corretas (tanto verdadeiros positivos quanto verdadeiros negativos) em relacÃßaÃÉo ao total de previsoÃÉes feitas. √â uma meÃÅtrica geral que indica a porcentagem de previsoÃÉes corretas feitas pelo modelo.\n",
        "\n",
        "        AcuraÃÅcia = (Verdadeiros positivos + Verdadeiros negativos) / Total de previsoÃÉes\n",
        "\n",
        "\n",
        "PrecisaÃÉo: A proporcÃßaÃÉo de verdadeiros positivos em relacÃßaÃÉo ao total de previsoÃÉes positivas feitas pelo modelo. Mede a exatidaÃÉo das previsoÃÉes positivas do modelo. EÃÅ particularmente uÃÅtil quando o custo de falsos positivos eÃÅ alto.\n",
        "\n",
        "        PrecisaÃÉo = Verdadeiros Positivos / (Verdadeiros Positivos + Falsos Positivos)\n",
        "\n",
        "\n",
        "Recall: √â a propor√ß√£o de verdadeiros positivos em rela√ß√£o ao total de positivos reais (verdadeiros positivos + falsos negativos). Mede a capacidade do modelo de identificar corretamente todas as inst√¢ncias positivas.\n",
        "\n",
        "        Recall = Verdadeiros Positivos / (Verdadeiros Positivos + Falsos Negativos)\n",
        "\n",
        "F1-Score: √â a m√©dia harm√¥nica da precis√£o e do recall. O F1-score √© uma m√©trica √∫til quando se precisa equilibrar precis√£o e recall, especialmente em situa√ß√µes onde h√° uma distribui√ß√£o desigual das classes.\n",
        "\n",
        "        F1-Score = 2 x (Precis√£o x Recall) / (Precis√£o + Recall)\n",
        "\n",
        "\n",
        "Isso permite uma avaliacÃßaÃÉo completa do desempenho do modelo, considerando diferentes aspectos importantes para a tarefa de¬†classificacÃßaÃÉo.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
